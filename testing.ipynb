{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "import ast\n",
    "from ast import AST\n",
    "import tokenize\n",
    "import token\n",
    "from numbers import Number\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-5a34ff29ca93>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-5a34ff29ca93>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    text = b'def%20tokenASTCombine(tok,%20astNode):%0A%20%20%20%20tok.pop(0)%0A%20%20%20%20nodeyList,%20looseTokenList,%20tk%20=%20zipTokAST(tok,%20astNode,%20%5B%5D)%20#skip%20start%20marker%20token%0A%20%20%20%20while(len(tk)%20%3E%201):%20#skip%20the%20end%20maker%0A%20%20%20%20%20%20%20%20if(tk%5B0%5D.type%20!=%20token.NEWLINE):%0A%20%20%20%20%20%20%20%20%20%20%20%20nodeyList.append(formatToken(tk%5B0%5D))%0A%20%20%20%20%20%20%20%20tk.pop(0)%0A%20%20%20%20return%20json.dumps(nodeyList)%0A%0A%0Adef%20formatToken(tk):%0A%20%20%20%20return%20%7B'type':%20token.tok_name%5Btk.type%5D,%20'start':%20%7B'line':%20tk.start%5B0%5D,%20'col':%20tk.start%5B1%5D%7D,%20'end':%20%7B'line':%20tk.end%5B0%5D,%20'col':%20tk.end%5B1%5D%7D,%20'literal':%20tk.string%7D%0A%0A%0Adef%20zipTokAST(tk,%20node,%20nodeyList):%0A%20%20%20%20if(len(tk)%20%3C%201%20or%20tk%5B0%5D.type%20==%20token.ENDMARKER):%0A%20%20%20%20%20%20%20%20return%20nodeyList,%20%5B%5D,%20%5B%5D%20#end%20of%20tokens%0A%20%20%20%20elif(node%20==%20None):%0A%20%20%20%20%20%20%20%20return%20nodeyList,%20%5B%5D,%20%5B%5D%20#end%20of%20nodes%0A%20%20%20%20%0A%20%20%20%20childrenZip%20=%20%5B%5D%0A%20%20%20%20for%20child%20in%20ast.iter_child_nodes(node):%20#depth%20fist%0A%20%20%20%20%20%20%20%20cz,%20tz,%20tk%20=%20zipTokAST(tk,%20child,%20%5B%5D)%0A%20%20%20%20%20%20%20%20if(len(tz)%20%3E%200):%0A%20%20%20%20%20%20%20%20%20%20%20%20childrenZip%20+=%20tz%0A%20%20%20%20%20%20%20%20if(len(cz)%20%3E%200):%0A%20%20%20%20%20%20%20%20%20%20%20%20childrenZip%20+=%20cz%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20marker%20=%20%7B'type':%20type(node).__name__,%20'content':%20childrenZip%7D%0A%20%20%20%20looseTokenList%20=%20%5B%5D%0A%20%20%20%20%0A%20%20%20%20if(hasattr(node,%20'lineno')):%20#meaning%20it's%20a%20node%20that%20appears%20in%20the%20text%0A%20%20%20%20%20%20%20%20line%20=%20node.lineno%0A%20%20%20%20%20%20%20%20col%20=%20node.col_offset%0A%20%20%20%20%20%20%20%20#print(%22node%20is%22,%20type(node).__name__,%20line,%20col,%20tk%5B0%5D)%0A%20%20%20%20%20%20%20%20#%20check%20for%20nodes%20that%20don't%20belong%20to%20anyone%0A%20%20%20%20%20%20%20%20while(len(tk)%20%3E%200%20and%20(tk%5B0%5D.start%5B0%5D%20%3C%20line%20or%20(tk%5B0%5D.start%5B0%5D%20==%20line%20and%20tk%5B0%5D.start%5B1%5D%20%3C%20col))):%20#actually%20starts%20before%20this%20node%0A%20%20%20%20%20%20%20%20%20%20%20%20if(tk%5B0%5D.type%20!=%20token.NEWLINE):%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20looseTokenList.append(formatToken(tk%5B0%5D))%0A%20%20%20%20%20%20%20%20%20%20%20%20tk.pop(0)%0A%20%20%20%20%20%20%20%20if(len(tk)%20%3E%200%20and%20tk%5B0%5D.start%5B0%5D%20==%20line%20and%20tk%5B0%5D.start%5B1%5D%20==%20col):%0A%20%20%20%20%20%20%20%20%20%20%20%20if(tk%5B0%5D.type%20!=%20token.NEWLINE):%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20formatted%20=%20formatToken(tk%5B0%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20marker%5B'start'%5D%20=%20formatted%5B'start'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20marker%5B'end'%5D%20=%20formatted%5B'end'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20marker%5B'literal'%5D%20=%20formatted%5B'literal'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20tk.pop(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20if('literal'%20in%20marker%20or%20len(childrenZip)%20%3E%200):%0A%20%20%20%20%20%20%20%20nodeyList.append(marker)%0A%20%20%0A%20%20%20%20return%20nodeyList,%20looseTokenList,%20tk%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20''\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "code = sys.argv[0]\n",
    "text = \"\"\n",
    "text = \"\"\n",
    "tree = ast.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = text.encode(\"unicode_escape\").decode(\"utf-8\")\n",
    "test = io.BytesIO(text.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('body', [])\n"
     ]
    }
   ],
   "source": [
    "for child in ast.iter_fields(tree):\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module([])\n"
     ]
    }
   ],
   "source": [
    "print(ast.dump(tree, False, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TokenInfo(type=59 (BACKQUOTE), string='utf-8', start=(0, 0), end=(0, 0), line=''), TokenInfo(type=0 (ENDMARKER), string='', start=(1, 0), end=(1, 0), line='')]\n"
     ]
    }
   ],
   "source": [
    "g = tokenize.tokenize(test.readline)\n",
    "tk = list(g)\n",
    "print(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenASTCombine(tok, astNode):\n",
    "    tok.pop(0)\n",
    "    nodeyList, looseTokenList, tk = zipTokAST(tok, astNode, []) #skip start marker token\n",
    "    while(len(tk) > 1): #skip the end maker\n",
    "        if(tk[0].type != token.NEWLINE):\n",
    "            nodeyList.append(formatToken(tk[0]))\n",
    "        tk.pop(0)\n",
    "    return json.dumps(nodeyList)\n",
    "\n",
    "\n",
    "def formatToken(tk):\n",
    "    return {'type': token.tok_name[tk.type], 'start': {'line': tk.start[0], 'col': tk.start[1]}, 'end': {'line': tk.end[0], 'col': tk.end[1]}, 'literal': tk.string}\n",
    "\n",
    "\n",
    "def zipTokAST(tk, node, nodeyList):\n",
    "    if(len(tk) < 1 or tk[0].type == token.ENDMARKER):\n",
    "        return nodeyList, [], [] #end of tokens\n",
    "    elif(node == None):\n",
    "        return nodeyList, [], [] #end of nodes\n",
    "    \n",
    "    childrenZip = []\n",
    "    for child in ast.iter_child_nodes(node): #depth fist\n",
    "        cz, tz, tk = zipTokAST(tk, child, [])\n",
    "        if(len(tz) > 0):\n",
    "            childrenZip += tz\n",
    "        if(len(cz) > 0):\n",
    "            childrenZip += cz\n",
    "        \n",
    "    marker = {'type': type(node).__name__, 'content': childrenZip}\n",
    "    looseTokenList = []\n",
    "    \n",
    "    if(hasattr(node, 'lineno')): #meaning it's a node that appears in the text\n",
    "        line = node.lineno\n",
    "        col = node.col_offset\n",
    "        #print(\"node is\", type(node).__name__, line, col, tk[0])\n",
    "        # check for nodes that don't belong to anyone\n",
    "        while(len(tk) > 0 and (tk[0].start[0] < line or (tk[0].start[0] == line and tk[0].start[1] < col))): #actually starts before this node\n",
    "            if(tk[0].type != token.NEWLINE):\n",
    "                looseTokenList.append(formatToken(tk[0]))\n",
    "            tk.pop(0)\n",
    "        if(len(tk) > 0 and tk[0].start[0] == line and tk[0].start[1] == col):\n",
    "            if(tk[0].type != token.NEWLINE):\n",
    "                formatted = formatToken(tk[0])\n",
    "                marker['start'] = formatted['start']\n",
    "                marker['end'] = formatted['end']\n",
    "                marker['literal'] = formatted['literal']\n",
    "            tk.pop(0)\n",
    "            \n",
    "    if('literal' in marker or len(childrenZip) > 0):\n",
    "        nodeyList.append(marker)\n",
    "  \n",
    "    return nodeyList, looseTokenList, tk\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"Module\", \"content\": [{\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 1, \"col\": 0}, \"end\": {\"line\": 1, \"col\": 6}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 1, \"col\": 7}, \"end\": {\"line\": 1, \"col\": 10}, \"literal\": \"sys\"}, {\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 2, \"col\": 0}, \"end\": {\"line\": 2, \"col\": 6}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 2, \"col\": 7}, \"end\": {\"line\": 2, \"col\": 10}, \"literal\": \"ast\"}, {\"type\": \"ImportFrom\", \"content\": [], \"start\": {\"line\": 3, \"col\": 0}, \"end\": {\"line\": 3, \"col\": 4}, \"literal\": \"from\"}, {\"type\": \"NAME\", \"start\": {\"line\": 3, \"col\": 5}, \"end\": {\"line\": 3, \"col\": 8}, \"literal\": \"ast\"}, {\"type\": \"NAME\", \"start\": {\"line\": 3, \"col\": 9}, \"end\": {\"line\": 3, \"col\": 15}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 3, \"col\": 16}, \"end\": {\"line\": 3, \"col\": 19}, \"literal\": \"AST\"}, {\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 4, \"col\": 0}, \"end\": {\"line\": 4, \"col\": 6}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 4, \"col\": 7}, \"end\": {\"line\": 4, \"col\": 15}, \"literal\": \"tokenize\"}, {\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 5, \"col\": 0}, \"end\": {\"line\": 5, \"col\": 6}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 5, \"col\": 7}, \"end\": {\"line\": 5, \"col\": 12}, \"literal\": \"token\"}, {\"type\": \"ImportFrom\", \"content\": [], \"start\": {\"line\": 6, \"col\": 0}, \"end\": {\"line\": 6, \"col\": 4}, \"literal\": \"from\"}, {\"type\": \"NAME\", \"start\": {\"line\": 6, \"col\": 5}, \"end\": {\"line\": 6, \"col\": 12}, \"literal\": \"numbers\"}, {\"type\": \"NAME\", \"start\": {\"line\": 6, \"col\": 13}, \"end\": {\"line\": 6, \"col\": 19}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 6, \"col\": 20}, \"end\": {\"line\": 6, \"col\": 26}, \"literal\": \"Number\"}, {\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 7, \"col\": 0}, \"end\": {\"line\": 7, \"col\": 6}, \"literal\": \"import\"}, {\"type\": \"NAME\", \"start\": {\"line\": 7, \"col\": 7}, \"end\": {\"line\": 7, \"col\": 11}, \"literal\": \"json\"}, {\"type\": \"Import\", \"content\": [], \"start\": {\"line\": 8, \"col\": 0}, \"end\": {\"line\": 8, \"col\": 6}, \"literal\": \"import\"}]}, {\"type\": \"NAME\", \"start\": {\"line\": 8, \"col\": 7}, \"end\": {\"line\": 8, \"col\": 9}, \"literal\": \"io\"}]\n"
     ]
    }
   ],
   "source": [
    "print(tokenASTCombine(tk, tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNodey(node):\n",
    "    jsn = {'type': type(node).__name__, 'node_uid': 0, 'content': []}\n",
    "\n",
    "    if(hasattr(node, 'lineno')): #meaning it's a node that appears in the text\n",
    "        jsn['line'] = node.lineno\n",
    "        jsn['col'] = node.col_offset\n",
    "\n",
    "    for child in ast.iter_child_nodes(node):\n",
    "        c = makeNodey(child)\n",
    "        if(c and jsn):\n",
    "            jsn['content'].append(c)\n",
    "\n",
    "    for field, value in ast.iter_fields(node):\n",
    "        #print(\"fiel?\", field, value)\n",
    "        if(isinstance(value, str) or isinstance(value, Number) or isinstance(value, bool)):\n",
    "            #print(\"fiel is\", field, value)\n",
    "            value = json.dumps(value)\n",
    "            if(len(jsn['content']) > 0): #add as a name Nodey\n",
    "                lit = {'type': 'Name', 'literal': value, 'node_uid': 0, 'content': [], 'line': node.lineno, 'col': node.col_offset}\n",
    "                jsn['content'].append(lit)\n",
    "            else:\n",
    "                jsn['literal'] = value\n",
    "\n",
    "    if(len(jsn['content']) > 0 or 'literal' in jsn):\n",
    "        return jsn\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"type\": \"Module\", \"node_uid\": 0, \"content\": [{\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"sys\\\\\"\"}], \"line\": 1, \"col\": 0}, {\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"ast\\\\\"\"}], \"line\": 2, \"col\": 0}, {\"type\": \"ImportFrom\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"AST\\\\\"\"}, {\"type\": \"Name\", \"literal\": \"\\\\\"ast\\\\\"\", \"node_uid\": 0, \"content\": [], \"line\": 3, \"col\": 0}, {\"type\": \"Name\", \"literal\": \"0\", \"node_uid\": 0, \"content\": [], \"line\": 3, \"col\": 0}], \"line\": 3, \"col\": 0}, {\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"tokenize\\\\\"\"}], \"line\": 4, \"col\": 0}, {\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"token\\\\\"\"}], \"line\": 5, \"col\": 0}, {\"type\": \"ImportFrom\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"Number\\\\\"\"}, {\"type\": \"Name\", \"literal\": \"\\\\\"numbers\\\\\"\", \"node_uid\": 0, \"content\": [], \"line\": 6, \"col\": 0}, {\"type\": \"Name\", \"literal\": \"0\", \"node_uid\": 0, \"content\": [], \"line\": 6, \"col\": 0}], \"line\": 6, \"col\": 0}, {\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"json\\\\\"\"}], \"line\": 7, \"col\": 0}, {\"type\": \"Import\", \"node_uid\": 0, \"content\": [{\"type\": \"alias\", \"node_uid\": 0, \"content\": [], \"literal\": \"\\\\\"io\\\\\"\"}], \"line\": 8, \"col\": 0}]}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsn = makeNodey(tree)\n",
    "json.dumps(jsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
