{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "import ast\n",
    "from ast import AST\n",
    "import tokenize\n",
    "import token\n",
    "from numbers import Number\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenASTCombine(tok, astNode):\n",
    "    tok.pop(0)\n",
    "    nodeyList, looseTokenList, tk = zipTokAST(tok, astNode, []) #skip start marker token\n",
    "    while(len(tk) > 1): #skip the end maker\n",
    "        if(tk[0].type != token.NEWLINE):\n",
    "            nodeyList.append(formatToken(tk[0]))\n",
    "        tk.pop(0)\n",
    "    return json.dumps(nodeyList)\n",
    "\n",
    "\n",
    "def formatToken(tk):\n",
    "    return {'type': token.tok_name[tk.type], 'start': {'line': tk.start[0], 'col': tk.start[1]}, 'end': {'line': tk.end[0], 'col': tk.end[1]}, 'literal': tk.string}\n",
    "\n",
    "\n",
    "def zipTokAST(tk, node, nodeyList):\n",
    "    if(len(tk) < 1 or tk[0].type == token.ENDMARKER):\n",
    "        return nodeyList, [], [] #end of tokens\n",
    "    elif(node == None):\n",
    "        return nodeyList, [], [] #end of nodes\n",
    "    \n",
    "    childrenZip = []\n",
    "    for child in ast.iter_child_nodes(node): #depth fist\n",
    "        cz, tz, tk = zipTokAST(tk, child, [])\n",
    "        if(len(tz) > 0):\n",
    "            childrenZip += tz\n",
    "        if(len(cz) > 0):\n",
    "            childrenZip += cz\n",
    "        \n",
    "    marker = {'type': type(node).__name__, 'content': childrenZip}\n",
    "    looseTokenList = []\n",
    "    \n",
    "    if(hasattr(node, 'lineno')): #meaning it's a node that appears in the text\n",
    "        line = node.lineno\n",
    "        col = node.col_offset\n",
    "        #print(\"node is\", type(node).__name__, line, col, tk[0])\n",
    "        # check for nodes that don't belong to anyone\n",
    "        while(len(tk) > 0 and (tk[0].start[0] < line or (tk[0].start[0] == line and tk[0].start[1] < col))): #actually starts before this node\n",
    "            if(tk[0].type != token.NEWLINE):\n",
    "                looseTokenList.append(formatToken(tk[0]))\n",
    "            tk.pop(0)\n",
    "        if(len(tk) > 0 and tk[0].start[0] == line and tk[0].start[1] == col):\n",
    "            if(tk[0].type != token.NEWLINE):\n",
    "                formatted = formatToken(tk[0])\n",
    "                marker['start'] = formatted['start']\n",
    "                marker['end'] = formatted['end']\n",
    "                marker['literal'] = formatted['literal']\n",
    "            tk.pop(0)\n",
    "            \n",
    "    if('literal' in marker or len(childrenZip) > 0):\n",
    "        nodeyList.append(marker)\n",
    "  \n",
    "    return nodeyList, looseTokenList, tk\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNodey(node):\n",
    "    jsn = {'type': type(node).__name__, 'node_uid': 0, 'content': []}\n",
    "\n",
    "    if(hasattr(node, 'lineno')): #meaning it's a node that appears in the text\n",
    "        jsn['line'] = node.lineno\n",
    "        jsn['col'] = node.col_offset\n",
    "\n",
    "    for child in ast.iter_child_nodes(node):\n",
    "        c = makeNodey(child)\n",
    "        if(c and jsn):\n",
    "            jsn['content'].append(c)\n",
    "\n",
    "    for field, value in ast.iter_fields(node):\n",
    "        #print(\"fiel?\", field, value)\n",
    "        if(isinstance(value, str) or isinstance(value, Number) or isinstance(value, bool)):\n",
    "            #print(\"fiel is\", field, value)\n",
    "            value = json.dumps(value)\n",
    "            if(len(jsn['content']) > 0): #add as a name Nodey\n",
    "                lit = {'type': 'Name', 'literal': value, 'node_uid': 0, 'content': [], 'line': node.lineno, 'col': node.col_offset}\n",
    "                jsn['content'].append(lit)\n",
    "            else:\n",
    "                jsn['literal'] = value\n",
    "\n",
    "    if(len(jsn['content']) > 0 or 'literal' in jsn):\n",
    "        return jsn\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCode(str):\n",
    "    #print(\"got code\", str)\n",
    "    code = str.encode('utf-8')\n",
    "    tree = ast.parse(str)\n",
    "    bytes = io.BytesIO(code)\n",
    "    g = tokenize.tokenize(bytes.readline)\n",
    "    tk = list(g)\n",
    "    print(tokenASTCombine(tk, tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Expr(value=Call(func=Name(id='formatToken', ctx=Load()), args=[Dict(keys=[Str(s='foo')], values=[Num(n=7)])], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='json', ctx=Load()), attr='dumps', ctx=Load()), args=[Name(id='jsn', ctx=Load())], keywords=[]))])\n"
     ]
    }
   ],
   "source": [
    "text = \"formatToken({'foo': 7})\\njson.dumps(jsn)\"\n",
    "tree = ast.parse(text)\n",
    "print(ast.dump(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
